{"cells":[{"cell_type":"markdown","metadata":{"id":"VdOwwVzv0aiR"},"source":["Introduction to Pre-Training and Transfer Learning for with RNNs\n","\n","In previous lessons, we built and trained RNNs from scratch. However in practice, this is not necessary or even encouraged, especially if you want to reduce time and cost, or have few labeled data points.\n","\n","In this module, we will learn about transfer learning in NLP. In convolutional neural nets, backbones are generally trained using one task, then fine-tuned on another task. The same is generally true with transfer learning in NLP, except that language models are generally used to do pre-training, instead of classification on ImageNet.\n","\n","As humans, we have an incredible capability. We know tens of thousands of words in our head, sometimes in many different tenses, conjugations, etc. Given the sentence below, my guess is that you will easily be able to complete the sentence with a word that make sense given the context.\n","\n","It snowed on the slopes today, it was a great day for ...\n","\n","You probably easily filled that word with something like skiing, snowboarding, sledding, etc. In language modeling, this what we're trying to teach the model how to do. We use an unsupervised approach to learning a language dataset by trying to predict the next word in a sequence. Given a sequence of words, \\(w_1, w_2 ... w_n\\), we try to correctly classify \\(w_{n+1}\\).\n","\n","Today, we fine-tune a pre-trained language model from fastai, then use it to classify movie reviews by sentiment. We will be following the general procedure outlined by Universal Language Model Fine-tuning for Text Classification (ULMFiT). A more detailed walkthrough of this procedure can be found in this chapter of the FastAI book chapter about transfer learning with RNNs. In FastAI, tokenization and numericalization are built in. Please see the book chapter linked for specifics on how it all works.\n","\n","The figure below is from the ULMFiT paper. This represents the training steps that they used to improve performance on text classification tasks using pre-training."]},{"cell_type":"markdown","metadata":{"id":"0he4_ImU0fys"},"source":["First, the authors trained a language model (AWD LSTM, the same one we'll use in this lesson, panel (a)). This model takes in a sequence of words as inputs and tries to predict the same sequence just shifted by one word (text generation). The input layer is an embedding, and the final layer is a linear classifier that predicts a probability distribution over the vocabulary for many times.\n","\n","Second, then fine-tuned that same language model on domain-specific datasets like IMDB (what we'll use today), and AG News (b).\n","\n","Finally, they removed the language model head and added an untrained classifier head (C). They trained the head only for a few epochs, then trained the entire model together. The authors found that this method significantly improved performance over untrained models.\n","\n","This technique is extremely useful because in NLP, unlabeled data is plentiful and cheap, but labeled data is scarce and expensive. This give us a ton of power to create classifiers for domain-specific datasets without having a ton of labeled examples.\n","\n","We will be replicating part of this work in today's lesson. We will load a language model that's already been trained on wikitext103 (We could train it ourselves, but this would take for ever). Then, we'll fine-tune the language model on movie reviews, including many that are unlabeled. Finally, we'll use just the labeled data to train a classifier."]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5247,"status":"ok","timestamp":1691714774426,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"},"user_tz":-420},"id":"m9ex7R3QJ3s_"},"outputs":[],"source":["!pip install -Uqq fastai"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5113,"status":"ok","timestamp":1691714779517,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"},"user_tz":-420},"id":"-JJstQtEKF7_"},"outputs":[],"source":["from fastai import *\n","from fastai.text.all import *\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from IPython.display import display, Markdown"]},{"cell_type":"markdown","metadata":{"id":"qeD_gHvk0ssd"},"source":["Dataloaders for Language Modeling\n","\n","In this lesson, we'll be using the IMDB dataset provided by fastai. This data has three folders with data we'll use to train the language model: train, test, and unsup. The train and test folders contain movie reviews organized into pos and neg folders, which serve as our labels. The unsup folder contains raw texts with no labels. This often mirrors the real world, where you have tons of data without labels but just a small amount of data with labels. This technique allows you to use all the data to learn from, even if you only have labels for part of it."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":158},"executionInfo":{"elapsed":43853,"status":"ok","timestamp":1691714823361,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"},"user_tz":-420},"id":"9azkSag8KPn3","outputId":"53a7a3b8-fbc1-42fa-fb0d-ed7e26322c0f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      <progress value='144441344' class='' max='144440600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      100.00% [144441344/144440600 00:12&lt;00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["[Path('/root/.fastai/data/imdb/tmp_clas'),\n"," Path('/root/.fastai/data/imdb/train'),\n"," Path('/root/.fastai/data/imdb/test'),\n"," Path('/root/.fastai/data/imdb/imdb.vocab'),\n"," Path('/root/.fastai/data/imdb/tmp_lm'),\n"," Path('/root/.fastai/data/imdb/unsup'),\n"," Path('/root/.fastai/data/imdb/README')]"]},"metadata":{},"execution_count":3}],"source":["# Download the data\n","path = untar_data(URLs.IMDB)\n","list(path.ls())"]},{"cell_type":"markdown","metadata":{"id":"FdTbquzM00VJ"},"source":["Let's take a look at a description of the dataset, from the README:\n","\n","Overview\n","\n","This dataset contains movie reviews along with their associated binary sentiment polarity labels. It is intended to serve as a benchmark for sentiment classification. This document outlines how the dataset was gathered, and how to use the files provided.\n","\n","Dataset\n","\n","The core dataset contains 50,000 reviews split evenly into 25k train and 25k test sets. The overall distribution of labels is balanced (25k pos and 25k neg). We also include an additional 50,000 unlabeled documents for unsupervised learning.\n","\n","In the entire collection, no more than 30 reviews are allowed for any given movie because reviews for the same movie tend to have correlated ratings. Further, the train and test sets contain a disjoint set of movies, so no significant performance is obtained by memorizing movie-unique terms and their associated with observed labels. In the labeled train/test sets, a negative review has a score <= 4 out of 10, and a positive review has a score >= 7 out of 10. Thus reviews with more neutral ratings are not included in the train/test sets. In the unsupervised set, reviews of any rating are included and there are an even number of reviews > 5 and <= 5."]},{"cell_type":"markdown","metadata":{"id":"K8U59HNu05Es"},"source":["In our first task of the day, we want to use unlabeled movie reviews and learn from them in a self-supervised way. We will use the train and unsup directories to fine-tune our language model, and the test directory to validate performance.\n","\n","In this case, we'll set up our task to predict the next word. This means that our targets will just be our inputs, shifted by one position. For example, let's consider the text: \"The quick brown fox jumped over the lazy dog.\" Let's consider a sequence length of 3, and mock our inputs and outputs in a manner that would set a model up to predict the next word.\n","\n","Inputs\tTarget\n","The quick brown\tquick brown fox\n","quick brown fox\tbrown fox jumped\n","brown fox jumped\tfox jumped over\n","fox jumped over\tover the lazy\n","over the lazy\tthe lazy dog\n","When we set up a task this way, this allows our model to learn about the data in the absence of labels! We'll come back to this concept in the next lesson as well, with a more math-y description.\n","\n","Let's create our dataloaders object and take a look at a batch. It has two columns - the column on the left is some text from movie reviews, and the right column of is that same text, just shifted by one word. Later on, using RNNs, we will attempt to generate the sequence on the right using the sequence on the left.\n","\n","NOTE: In previous lectures, we created our own vocab and tokenizers. These are built in with TextDataLoaders. When we call dls.one_batch(), we see that we get word indices. If you want to examine the vocab and tokenizer, the dls object will have a .vocab and a .tokenizer method you can explore."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":446819,"status":"ok","timestamp":1691715270174,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"},"user_tz":-420},"id":"_WWjGTs33JkE","outputId":"1df6e60b-6846-4147-aa3b-fdc18235b73b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}}],"source":["get_imdb = partial(get_text_files, folders=['train', 'unsup'])\n","\n","lm_dls = DataBlock(\n","    blocks=TextBlock.from_folder(path, is_lm=True),\n","    get_items=get_imdb, splitter=RandomSplitter(0.1)\n",").dataloaders(path, path=path)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":216},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1691715270177,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"},"user_tz":-420},"id":"gxJ4hen938hi","outputId":"e194cdac-a2bb-49f4-b20e-ecf781909f26"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>text_</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>xxbos xxmaj this movie was one of the first made after the xxup mpaa rating system replaced the xxmaj hayes code , and people could make porn commercially . xxmaj originally , it got an x rating , and they trimmed it down a bit to give it an xxup r. \\n\\n xxmaj basically , it parodies the xxmaj flash xxmaj gordan serials of the 1930 's , with stop - motion</td>\n","      <td>xxmaj this movie was one of the first made after the xxup mpaa rating system replaced the xxmaj hayes code , and people could make porn commercially . xxmaj originally , it got an x rating , and they trimmed it down a bit to give it an xxup r. \\n\\n xxmaj basically , it parodies the xxmaj flash xxmaj gordan serials of the 1930 's , with stop - motion animation</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>the xxmaj soviet xxmaj union . xxmaj so , xxmaj holly xxmaj hunter protested xxmaj kazan for something that happened 50 years ago . \\n\\n i think there are many fine actresses that could have played xxmaj hunter 's role and because of her anti - american positions , i think the role should have been given to someone else . xxmaj otherwise , i would have rated the film higher .</td>\n","      <td>xxmaj soviet xxmaj union . xxmaj so , xxmaj holly xxmaj hunter protested xxmaj kazan for something that happened 50 years ago . \\n\\n i think there are many fine actresses that could have played xxmaj hunter 's role and because of her anti - american positions , i think the role should have been given to someone else . xxmaj otherwise , i would have rated the film higher . \\n\\n</td>\n","    </tr>\n","  </tbody>\n","</table>"]},"metadata":{}}],"source":["lm_dls.show_batch(max_n=2)"]},{"cell_type":"markdown","metadata":{"id":"VxW0YVkv1ALf"},"source":["As we can see in the block below, the inputs are a block of text, and the outputs we're trying to predict is that text shifted by one token. This is similar to the setup in the previous module where we built RNNs from scratch to predict time series data. The benefit of this setup is that the model can learn about the data in the absence of labels.\n","\n","Now, let's look at a single batch of numericalized data. We should make sure that y is x shifted by 1."]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":727,"status":"ok","timestamp":1691715270892,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"},"user_tz":-420},"id":"7vLJCANZMrqc"},"outputs":[],"source":["x, y = lm_dls.one_batch()"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1691715270893,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"},"user_tz":-420},"id":"vbLyhkRfzbBC","outputId":"1bfe8e1f-e4a7-40fc-a816-2faa99500ca6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["LMTensorText([    2,     8,    20,    30,    62,   298,   100,     8,  4281,\n","                519,   135,  1244,    24,  2692,   471,   135,   658,    24,\n","                 18,   138,   135,    13,   580,    24,   144,    21,  1064,\n","                 15,  3787,    13,   227,    14,  1134,   158,   104,    13,\n","                131,   369,    10,     8,   308,  3560,     9,  3104,    15,\n","                159,    75,    11,    75,    11,    75,    10,     8,   257,\n","                 21,   254,    42,    99,  1957,    61,    74,    42, 14824,\n","                 99,   147,    94,    65,    25,  1957,    18,    10,     8],\n","             device='cuda:0')"]},"metadata":{},"execution_count":7}],"source":["x[0]"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1691715270894,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"},"user_tz":-420},"id":"mvX8nxKNzchr","outputId":"86ce2950-0d27-4bee-ea1e-ebe6183c6c69"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorText([    8,    20,    30,    62,   298,   100,     8,  4281,   519,\n","              135,  1244,    24,  2692,   471,   135,   658,    24,    18,\n","              138,   135,    13,   580,    24,   144,    21,  1064,    15,\n","             3787,    13,   227,    14,  1134,   158,   104,    13,   131,\n","              369,    10,     8,   308,  3560,     9,  3104,    15,   159,\n","               75,    11,    75,    11,    75,    10,     8,   257,    21,\n","              254,    42,    99,  1957,    61,    74,    42, 14824,    99,\n","              147,    94,    65,    25,  1957,    18,    10,     8,  1373],\n","           device='cuda:0')"]},"metadata":{},"execution_count":8}],"source":["y[0]"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1691715270894,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"},"user_tz":-420},"id":"wWP93cDAzeBW"},"outputs":[],"source":["# Check that the same shift occurs for the entire batch\n","assert (x[:, 1:] == y[:, :-1]).all()"]},{"cell_type":"markdown","metadata":{"id":"sq8AfL9V1Hn-"},"source":["It looks like all our assumptions are true! In this lesson, we learned how data is organized for language modeling. Finally, we created our dataloaders object and examined a batch of data."]},{"cell_type":"markdown","metadata":{"id":"H2Mx0UmS1O3I"},"source":["Creating a language model\n","\n","We will use fastai to train a language model. We'll ask the language model to predict the next word to learn this dataset. We're actually starting with a pre-trained model to begin with. When passing pretrained=True to language_model_learner, we load weights for a language model that was trained on the wikitext103 dataset. Then, like the ULMFiT paper, we will fine tune this language model on the IMDB dataset."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"executionInfo":{"elapsed":14290,"status":"ok","timestamp":1691715285177,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"},"user_tz":-420},"id":"vHUnq2AFM07o","outputId":"ea67b2a3-8918-418a-b3e3-e0a886eaec3a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      <progress value='105070592' class='' max='105067061' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      100.00% [105070592/105067061 00:09&lt;00:00]\n","    </div>\n","    "]},"metadata":{}}],"source":["lm_learn = language_model_learner(lm_dls, AWD_LSTM, pretrained=True)"]},{"cell_type":"markdown","metadata":{"id":"TG1_a5iR1Tdn"},"source":["In this exercise, we are training a neural network architecture called AWD LSTM. It should be fairly recognizable to you - there's an embedding layer, three LSTM layers, and a linear layer at the end that classifies each word. The special thing about this network is that it has dropout applied in many different places. Let's take a look at the model below."]},{"cell_type":"markdown","metadata":{"id":"wGKfNRzt1ehf"},"source":["As mentioned above, the pre-trained model was trained on data from Wikipedia. We should't expect it to complete movie reviews in a way that makes sense. In the cell below, we generate some text beginning with \"This movie was terrible,\" to see how well it works. It is able to generate some text, but it doesn't read like a movie review. We'll try this again once we've fine-tuned the model on some movie reviews."]},{"cell_type":"markdown","metadata":{"id":"flzNR5LV1em-"},"source":["Let's fine tune our model on IMDB reviews. Since we don't require labels, we can use the large amount of reviews in the unsup directory. This is similar to real-world NLP, where you may have many unlabeled instances but only a few labels. This technique allows you to learn from unlabeled data as well as labeled data!"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45,"status":"ok","timestamp":1691715285181,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"},"user_tz":-420},"id":"_g6fFRDlNG7u","outputId":"0cc924ee-7386-4354-f95b-5d4d7d68f5b6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["SequentialRNN(\n","  (0): AWD_LSTM(\n","    (encoder): Embedding(60008, 400, padding_idx=1)\n","    (encoder_dp): EmbeddingDropout(\n","      (emb): Embedding(60008, 400, padding_idx=1)\n","    )\n","    (rnns): ModuleList(\n","      (0): WeightDropout(\n","        (module): LSTM(400, 1152, batch_first=True)\n","      )\n","      (1): WeightDropout(\n","        (module): LSTM(1152, 1152, batch_first=True)\n","      )\n","      (2): WeightDropout(\n","        (module): LSTM(1152, 400, batch_first=True)\n","      )\n","    )\n","    (input_dp): RNNDropout()\n","    (hidden_dps): ModuleList(\n","      (0-2): 3 x RNNDropout()\n","    )\n","  )\n","  (1): LinearDecoder(\n","    (decoder): Linear(in_features=400, out_features=60008, bias=True)\n","    (output_dp): RNNDropout()\n","  )\n",")"]},"metadata":{},"execution_count":11}],"source":["lm_learn.model"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":3987,"status":"ok","timestamp":1691715289127,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"},"user_tz":-420},"id":"ALRYmzTVSZmg","outputId":"a219dcf8-f7ae-41ea-d177-268b4ef585d0"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["'This movie was terrible , but the only good thing to do was to make'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}],"source":["# The model is trained on wikitext, so it will be able to\n","# generate semi-sensible sentences, but they will likely\n","# have nothing to do with movies.\n","lm_learn.predict('This movie was terrible, ', n_words=10)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1691715289129,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"},"user_tz":-420},"id":"t4ZtYSwHNT1L"},"outputs":[],"source":["LR = 1e-3"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"elapsed":2456799,"status":"ok","timestamp":1691717745906,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"},"user_tz":-420},"id":"0D8I3jgONkYx","outputId":"8758718e-3cc0-4118-f5b8-b78d9b2f94e8"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>4.432985</td>\n","      <td>4.097354</td>\n","      <td>40:55</td>\n","    </tr>\n","  </tbody>\n","</table>"]},"metadata":{}}],"source":["lm_learn.fit_one_cycle(1, LR)"]},{"cell_type":"markdown","metadata":{"id":"eVUJOJpc1mMj"},"source":["Now that we've fine-tuned the language model a bit, it can generate text related to movies quite well."]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1691717745908,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"},"user_tz":-420},"id":"71zVnOptNpiW","outputId":"528ab1a2-bb0f-4cfc-8eb2-7135bc113d0f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["'This movie was terrible , fairly early in its career and regarded as one of'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}],"source":["lm_learn.predict('This movie was terrible, ', n_words=10)"]},{"cell_type":"markdown","metadata":{"id":"saS6qBZD1pFD"},"source":["Finally, let's save our model. We will use parts of this model in the next lesson to perform sentiment analysis on labeled movie reviews."]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":717,"status":"ok","timestamp":1691717746615,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"},"user_tz":-420},"id":"3dXm-EP7bj2Z"},"outputs":[],"source":["# Save the model\n","lm_learn.save_encoder('lm_encoder')"]},{"cell_type":"markdown","metadata":{"id":"zxGCAOwH1vL8"},"source":["Transfer Learning\n","\n","Let's review what we've done so far. We've taken a language model trained on wikitext103, and fine-tuned that language model on a bunch of unlabeled data (text from movie reviews).\n","\n","We will take the backbone of the model we learned, remove the language model head, and attach an untrained classifier. Just like we did with image models, we will freeze the parameters of the backbone and train the classifier, then we will unfreeze all the parameters and train the model all together for a number of epochs."]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":3263,"status":"ok","timestamp":1691717749875,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"},"user_tz":-420},"id":"bywruUvrbEUV"},"outputs":[],"source":["# Create dataloaders for text classification.\n","# Let's make sure to pass our vocab from our pre-training\n","# so the word indices are the same.\n","dls = TextDataLoaders.from_folder(path, train='train', valid='test', text_vocab=lm_dls.vocab)"]},{"cell_type":"markdown","metadata":{"id":"U5qMXW1J1zBJ"},"source":["Let's set up our model for training. First, we add a few callbacks to save the model and stop it if the validation loss plateaus."]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1691717750414,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"},"user_tz":-420},"id":"eSlZwbrtb3jW","outputId":"86fbd83b-1679-4879-a259-91a2453eb80c"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>category</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>xxbos xxmaj match 1 : xxmaj tag xxmaj team xxmaj table xxmaj match xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley vs xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley started things off with a xxmaj tag xxmaj team xxmaj table xxmaj match against xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit . xxmaj according to the rules of the match , both opponents have to go through tables in order to get the win . xxmaj benoit and xxmaj guerrero heated up early on by taking turns hammering first xxmaj spike and then xxmaj bubba xxmaj ray . a xxmaj german xxunk by xxmaj benoit to xxmaj bubba took the wind out of the xxmaj dudley brother . xxmaj spike tried to help his brother , but the referee restrained him while xxmaj benoit and xxmaj guerrero</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>xxbos xxmaj warning : xxmaj does contain spoilers . \\n\\n xxmaj open xxmaj your xxmaj eyes \\n\\n xxmaj if you have not seen this film and plan on doing so , just stop reading here and take my word for it . xxmaj you have to see this film . i have seen it four times so far and i still have n't made up my mind as to what exactly happened in the film . xxmaj that is all i am going to say because if you have not seen this film , then stop reading right now . \\n\\n xxmaj if you are still reading then i am going to pose some questions to you and maybe if anyone has any answers you can email me and let me know what you think . \\n\\n i remember my xxmaj grade 11 xxmaj english teacher quite well . xxmaj</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>xxbos xxrep 3 * xxup spoilers xxrep 3 * xxrep 3 * xxup spoilers xxrep 3 * xxmaj continued â€¦ \\n\\n xxmaj from here on in the whole movie collapses in on itself . xxmaj first we meet a rogue program with the indication we 're gon na get ghosts and vampires and werewolves and the like . xxmaj we get a guy with a retarded accent talking endless garbage , two ' ghosts ' that serve no real purpose and have no character what - so - ever and a bunch of henchmen . xxmaj someone 's told me they 're vampires ( straight out of xxmaj blade 2 ) , but they 're so undefined i did n't realise . \\n\\n xxmaj the funny accented guy with a ridiculous name suffers the same problem as the xxmaj oracle , only for far longer and far far worse .</td>\n","      <td>neg</td>\n","    </tr>\n","  </tbody>\n","</table>"]},"metadata":{}}],"source":["dls.show_batch(max_n=3)"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1691717750415,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"},"user_tz":-420},"id":"JkZVWtvMdLNg"},"outputs":[],"source":["cbs = [\n","    EarlyStoppingCallback(),\n","    SaveModelCallback()\n","]"]},{"cell_type":"markdown","metadata":{"id":"zRnRQTn01131"},"source":["In the cell below, we create our learner object using our dataloaders for the text classification task and the AWD_LSTM architecture."]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":1545,"status":"ok","timestamp":1691717751949,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"},"user_tz":-420},"id":"hIJhNvUZcELQ"},"outputs":[],"source":["# Create a learner for text classification.\n","learn = text_classifier_learner(dls, AWD_LSTM, metrics=[accuracy, error_rate], cbs=cbs)"]},{"cell_type":"markdown","metadata":{"id":"LjjipYDJ14tZ"},"source":["At this point, our model is the same model that's been pre-trained on wikitext-103, but we want to use the model we fine-tuned on IMDB. We can use the load_encoder method to load the weights we saved. After running this cell, we have an encoder that has been fine-tuned on movie reviews, and an untrained classification head."]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1691717751950,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"},"user_tz":-420},"id":"vTTf8YJNcbTp"},"outputs":[],"source":["# Load our weights from fine-tuning on full IMDB\n","learn = learn.load_encoder('lm_encoder')"]},{"cell_type":"markdown","metadata":{"id":"BnDT3rtJ17hT"},"source":["Let's fine tune our model for 10 epochs. This means that we will train the classifier only for 1 epoch, then unfreeze the entire model and train for 10 epochs (unless we meet our early stopping criteria)."]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":471},"id":"TmGgUoCDczAD","outputId":"cb0f1640-59f7-43c5-f6a0-21e168a326e1","executionInfo":{"status":"ok","timestamp":1691721337683,"user_tz":-420,"elapsed":3585738,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>error_rate</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>0.418362</td>\n","      <td>0.347071</td>\n","      <td>0.850200</td>\n","      <td>0.149800</td>\n","      <td>03:45</td>\n","    </tr>\n","  </tbody>\n","</table>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Better model found at epoch 0 with valid_loss value: 0.3470709025859833.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>error_rate</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>0.357849</td>\n","      <td>0.295298</td>\n","      <td>0.875560</td>\n","      <td>0.124440</td>\n","      <td>07:56</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.326391</td>\n","      <td>0.264898</td>\n","      <td>0.891680</td>\n","      <td>0.108320</td>\n","      <td>07:56</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.288138</td>\n","      <td>0.244958</td>\n","      <td>0.900960</td>\n","      <td>0.099040</td>\n","      <td>07:57</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.258267</td>\n","      <td>0.236319</td>\n","      <td>0.907680</td>\n","      <td>0.092320</td>\n","      <td>07:57</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.239012</td>\n","      <td>0.223134</td>\n","      <td>0.909280</td>\n","      <td>0.090720</td>\n","      <td>07:55</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.231084</td>\n","      <td>0.212122</td>\n","      <td>0.916000</td>\n","      <td>0.084000</td>\n","      <td>07:57</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.216249</td>\n","      <td>0.213874</td>\n","      <td>0.914720</td>\n","      <td>0.085280</td>\n","      <td>07:56</td>\n","    </tr>\n","  </tbody>\n","</table>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Better model found at epoch 0 with valid_loss value: 0.29529812932014465.\n","Better model found at epoch 1 with valid_loss value: 0.26489800214767456.\n","Better model found at epoch 2 with valid_loss value: 0.24495801329612732.\n","Better model found at epoch 3 with valid_loss value: 0.2363191545009613.\n","Better model found at epoch 4 with valid_loss value: 0.22313383221626282.\n","Better model found at epoch 5 with valid_loss value: 0.21212154626846313.\n","No improvement since epoch 5: early stopping\n"]}],"source":["learn.fine_tune(10, 1e-3)"]},{"cell_type":"markdown","metadata":{"id":"ty-suRPW2Avr"},"source":["Sanity check: If we give it obviously bad or obviously good movie reviews, does this model work?"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"qmUKkNbYc3Lw","colab":{"base_uri":"https://localhost:8080/","height":175},"executionInfo":{"status":"error","timestamp":1691722979427,"user_tz":-420,"elapsed":7,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"}},"outputId":"a89cf546-27da-479e-e72d-20d220ba86ac"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-3bccf4dcb0ac>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This movie was horrible!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'learn' is not defined"]}],"source":["learn.predict('This movie was horrible!')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uBU-H5x_zgDd","executionInfo":{"status":"aborted","timestamp":1691722979428,"user_tz":-420,"elapsed":6,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"}}},"outputs":[],"source":["learn.predict('This movie was great!')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0H_8IrkzYFE1","executionInfo":{"status":"aborted","timestamp":1691722979429,"user_tz":-420,"elapsed":7,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"}}},"outputs":[],"source":["learn.save('clf_fine_tuned')"]},{"cell_type":"markdown","metadata":{"id":"eUxkOz2u2Dt0"},"source":["Finally, let's do a bit of model evaluation. Let's take a look at the confusion matrix for the validation dataset. For this, we'll use fastai's ClassificationInterpretation object."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"s_ILus5NK0Eq","colab":{"base_uri":"https://localhost:8080/","height":175},"executionInfo":{"status":"error","timestamp":1691722989008,"user_tz":-420,"elapsed":8,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"}},"outputId":"8bea0ec4-2786-401d-bb7e-37f20861cd4c"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-aa7f7b70a42b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minterp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassificationInterpretation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'ClassificationInterpretation' is not defined"]}],"source":["interp = ClassificationInterpretation.from_learner(learn)"]},{"cell_type":"markdown","metadata":{"id":"Sd7EMPyD2GYy"},"source":["Once you've instantiated the interpreter object, you can easily analyze your model's performance. From the confusion matrix below, we can see that the false positive rate and false negative rate are relatively similar."]},{"cell_type":"code","execution_count":27,"metadata":{"id":"6xGqBUaaLypH","colab":{"base_uri":"https://localhost:8080/","height":506},"executionInfo":{"status":"ok","timestamp":1691721565460,"user_tz":-420,"elapsed":111288,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"}},"outputId":"1777bdd7-69e7-439e-fd2f-e74980ca4ef4"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["interp.plot_confusion_matrix()"]},{"cell_type":"markdown","metadata":{"id":"bn1Gqub42JRL"},"source":["Another useful way to analyze your model qualitatively is to examine the top losses. This is where the inference differs from the label most strongly, and can be useful in identifying samples that might be mis-labeled. Let's take a look at them below. Are any of these labels confusing or possibly wrong?"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"pvT0MgA3iqa6","colab":{"base_uri":"https://localhost:8080/","height":866},"executionInfo":{"status":"ok","timestamp":1691721566197,"user_tz":-420,"elapsed":753,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"}},"outputId":"f1bda8d2-3083-4288-f092-1308dbaa553a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input</th>\n","      <th>target</th>\n","      <th>predicted</th>\n","      <th>probability</th>\n","      <th>loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>xxbos * * spoilers xxup ahead * * \\n\\n xxmaj it is really unfortunate that a movie so well produced turns out to be \\n\\n such a disappointment . i thought this was full of ( silly ) clichÃ©s and \\n\\n that it basically tried to hard . \\n\\n xxmaj to the ( american ) guys out there : how many of you spend your \\n\\n time jumping on your girlfriend 's bed and making monkey \\n\\n sounds ? xxmaj to the ( married ) girls : how many of you have suddenly \\n\\n gone from prudes to xxunk overnight -- but not with your \\n\\n husband ? xxmaj to the xxmaj french : would you really ask about someone \\n\\n being \" Ã  la xxunk \" when you know they do n't speak xxmaj french ? xxmaj would n't \\n\\n you use a more common word like \" xxunk</td>\n","      <td>pos</td>\n","      <td>neg</td>\n","      <td>0.9996298551559448</td>\n","      <td>11.45113468170166</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>xxbos xxmaj with the plethora of repetitive and derivative sitcoms jamming fall , summer , winter and spring line - ups , it 's nice to see a show that sets itself from the lot in more than one area . \\n\\n ' earl ' takes an unusual approach . xxmaj it 's not about the \" daily musings of an eccentric family \" ( xxrep 4 z .. ) nor about the other boring stuff you see everywhere in sitcoms . xxmaj the show is about this small - time white trash thief ( earl ) who scratches off a lottery card and scores big time . xxmaj right at that moment , ' karma ' took it away from him . xxmaj overtime , he learns that that unusual incident was probably because of all the bad things he 's been doing , so he sets off on</td>\n","      <td>neg</td>\n","      <td>pos</td>\n","      <td>0.9996950626373291</td>\n","      <td>10.688621520996094</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>xxbos i went to see this 3 nights ago here in xxmaj cork , xxmaj ireland . xxmaj it was the world premiere of it , in the tiny cinema in the xxmaj xxunk xxmaj arts xxmaj centre as part of the xxmaj cork xxmaj film xxmaj festival . \\n\\n i found \" strange xxmaj fruit \" to be an excellent movie . xxmaj it is a bit rough around the edges , but for a low - budget movie that is to be expected ! xxmaj in general the acting ( particularly from the main lead xxmaj kent xxmaj xxunk ) is wonderful , the cinematography and direction excellent , and the script hugely entertaining and thought - provoking , with some nice set - ups and witty dialogue . \\n\\n xxmaj the ending was a bit sudden , with no conclusion given to characters and events once the</td>\n","      <td>neg</td>\n","      <td>pos</td>\n","      <td>0.9999772310256958</td>\n","      <td>8.966154098510742</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>xxbos xxmaj first off let me say , xxmaj if you have n't enjoyed a xxmaj van xxmaj damme movie since bloodsport , you probably will not like this movie . xxmaj most of these movies may not have the best plots or best actors but i enjoy these kinds of movies for what they are . xxmaj this movie is much better than any of the movies the other action guys ( segal and xxmaj dolph ) have thought about putting out the past few years . xxmaj van xxmaj damme is good in the movie , the movie is only worth watching to xxmaj van xxmaj damme fans . xxmaj it is not as good as xxmaj wake of xxmaj death ( which i highly recommend to anyone of likes xxmaj van xxmaj damme ) or xxmaj in hell but , in my opinion it 's worth watching</td>\n","      <td>neg</td>\n","      <td>pos</td>\n","      <td>0.9994433522224426</td>\n","      <td>8.366613388061523</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>xxbos xxmaj this movie was pure genius . xxmaj john xxmaj waters is brilliant . xxmaj it is hilarious and i am not sick of it even after seeing it about 20 times since i bought it a few months ago . xxmaj the acting is great , although xxmaj ricki xxmaj lake could have been better . xxmaj and xxmaj johnny xxmaj depp is magnificent . xxmaj he is such a beautiful man and a very talented actor . xxmaj and seeing most of xxmaj johnny 's movies , this is probably my favorite . i give it 9.5 / 10 . xxmaj rent it today !</td>\n","      <td>neg</td>\n","      <td>pos</td>\n","      <td>0.99998939037323</td>\n","      <td>8.33171558380127</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>xxbos xxmaj this film has the language , the style and the attitude down â€¦ plus greats rides from xxmaj xxunk ( a world champ ) and the great xxmaj jerry xxmaj lopez . xxmaj john xxmaj philbin as xxmaj turtle has the surf pidgin down , and the surfing scenes are still the best ever . a true classic that can be seen many times . xxmaj nia xxmaj peeples is a babe , and xxmaj laird xxmaj hamilton shows the early stuff that has made him the world 's number one extreme surfer .</td>\n","      <td>neg</td>\n","      <td>pos</td>\n","      <td>0.9997674822807312</td>\n","      <td>8.095316886901855</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>xxbos i was pleasantly surprised with this one . xxmaj it 's actually quite interesting and engaging . xxmaj the cast is strong , even xxmaj dan xxmaj cortese . xxmaj brooke xxmaj shields has come into her own as an actress . xxmaj black and xxmaj white must have really set her free , 'cause i have never seen her in this much command playing a conventional character . xxmaj if marketed right , could be a medium - size hit .</td>\n","      <td>neg</td>\n","      <td>pos</td>\n","      <td>0.9997592568397522</td>\n","      <td>7.901538848876953</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>xxbos xxmaj this is definitely one of the best xxmaj kung fu movies in the history of xxmaj cinema . xxmaj the screenplay is really well done ( which is not often the case for this type of movies ) and you can see that xxmaj chuck ( in one of his first xxunk a great actor . xxmaj the final fight with the xxunk deputy in the bullring is a masterpiece !</td>\n","      <td>neg</td>\n","      <td>pos</td>\n","      <td>0.9998723268508911</td>\n","      <td>7.846628665924072</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>xxbos xxmaj well , i must say , i initially found this short to be quite average , but having watched it nearly 5 times since ( its constantly shown on xxup ifc ) , xxmaj i 've developed an enjoyment of the simple plot elements and reality of the situations presented . xxmaj sofia xxmaj coppola contributes a solid addition to the category .</td>\n","      <td>neg</td>\n","      <td>pos</td>\n","      <td>0.9996089339256287</td>\n","      <td>7.693251132965088</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>xxbos i really liked this quirky movie . xxmaj the characters are not the bland beautiful people that show up in so many movies and on xxup tv . xxmaj it has a realistic edge , with a captivating story line . xxmaj the main title sequence alone makes this movie fun to watch .</td>\n","      <td>neg</td>\n","      <td>pos</td>\n","      <td>0.9958475828170776</td>\n","      <td>7.4936065673828125</td>\n","    </tr>\n","  </tbody>\n","</table>"]},"metadata":{}}],"source":["interp.plot_top_losses(10)"]},{"cell_type":"markdown","metadata":{"id":"SgMABEyw2QJF"},"source":["Sanity Checks and Experiments\n","\n","To make sure this is working, I want to know two things:\n","\n","Does our fine-tuned model outperform a model trained from scratch?\n","Does our fine-tuned model outperform a model that's only trained on wikitext103?"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"Cz6KTZeq8XW3","executionInfo":{"status":"ok","timestamp":1691721566197,"user_tz":-420,"elapsed":5,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"}}},"outputs":[],"source":["cbs = [\n","    EarlyStoppingCallback(),\n","    SaveModelCallback()\n","]"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"AYitiaKC8Sx3","executionInfo":{"status":"ok","timestamp":1691721566800,"user_tz":-420,"elapsed":607,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"}}},"outputs":[],"source":["control = text_classifier_learner(dls, AWD_LSTM, pretrained=False, metrics=[accuracy, error_rate], cbs=cbs).to_fp16()"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"BqhFD98D8l5L","colab":{"base_uri":"https://localhost:8080/","height":227},"executionInfo":{"status":"ok","timestamp":1691721961501,"user_tz":-420,"elapsed":394709,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"}},"outputId":"9eac6500-6b05-4a7a-dd0f-b2d441f775b0"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>error_rate</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>0.706292</td>\n","      <td>0.692045</td>\n","      <td>0.499720</td>\n","      <td>0.500280</td>\n","      <td>01:32</td>\n","    </tr>\n","  </tbody>\n","</table>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Better model found at epoch 0 with valid_loss value: 0.6920453310012817.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>error_rate</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>0.602544</td>\n","      <td>0.612011</td>\n","      <td>0.647160</td>\n","      <td>0.352840</td>\n","      <td>02:27</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.540196</td>\n","      <td>0.516118</td>\n","      <td>0.754200</td>\n","      <td>0.245800</td>\n","      <td>02:28</td>\n","    </tr>\n","  </tbody>\n","</table>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Better model found at epoch 0 with valid_loss value: 0.612011194229126.\n","Better model found at epoch 1 with valid_loss value: 0.5161178708076477.\n"]}],"source":["control.fine_tune(2, base_lr=1e-3)"]},{"cell_type":"markdown","metadata":{"id":"betS0RsM2UTt"},"source":["It seems pretty clear that the this method did not outperform our fine-tuned model. What about the a model just pre-trained on wikitext103?"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"H3GoEfV3_XIF","executionInfo":{"status":"ok","timestamp":1691721961501,"user_tz":-420,"elapsed":17,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"}}},"outputs":[],"source":["cbs = [\n","    EarlyStoppingCallback(),\n","    SaveModelCallback()\n","]"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"PtoPnV_V_myZ","executionInfo":{"status":"ok","timestamp":1691721963278,"user_tz":-420,"elapsed":1792,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"}}},"outputs":[],"source":["control = text_classifier_learner(dls, AWD_LSTM, pretrained=True, metrics=[accuracy, error_rate], cbs=cbs).to_fp16()"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"7A3a5ubD_pny","colab":{"base_uri":"https://localhost:8080/","height":175},"executionInfo":{"status":"error","timestamp":1691723005131,"user_tz":-420,"elapsed":5,"user":{"displayName":"Xabi Sagarzazu","userId":"11788458476726030662"}},"outputId":"38cce74c-ee50-4ace-d9e2-74b183004e64"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-df92835b821c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfine_tune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'control' is not defined"]}],"source":["control.fine_tune(2, base_lr=1e-3)"]},{"cell_type":"markdown","metadata":{"id":"nuVLyegu2XYb"},"source":["It also looks like fine-tuning on our domain-specific dataset helped as well, but the most important thing is to start with a pre-trained model in the first place."]},{"cell_type":"markdown","metadata":{"id":"7H8zBqaD4-TX"},"source":["# Exercise 17.1\n","\n","In this exercise, you will perform an experiment of your own.\n","We want to know how much of a head-start starting with a pre-trained model gives us in our fine-tuning step.\n","In this exercise, train two language models - one that is pre-trained, and one that is not - on the `train` and `unsup` directories.\n","Feel free to use the `lm_dls` we defined earlier, or practice creating your own.\n","After the same number of epochs, is the loss lower with the pre-trained model?\n","\n","<!-- startquestion -->"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xCgEmjYY5f_1"},"outputs":[],"source":["# Your code here"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ZQExfxrOLIF"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/mgfrantz/CodingNomads-Intro-To-Deep-Learning-Labs/blob/master/17_PreTrainingAndTransferLearning_workset.ipynb","timestamp":1691660383977}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}